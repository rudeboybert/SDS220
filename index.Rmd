---
title: "SDS/MTH 220: Intro to Probability and Statistics"
author: "Sec01: Albert Y. Kim & David Rockoff. Sec02: Katherine Kinnaird & Will Hopper"
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    df_print: paged
    includes:
      in_header: "favicon.html"
---

<style>
h1{font-weight: 400;}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=TRUE, 
  message=FALSE, 
  warning=FALSE, 
  eval=FALSE, 
  fig.width=16/2, 
  fig.height=9/2
)
library(tidyverse)
library(lubridate)
library(stringr)
library(forcats)
library(moderndive)

# Formating packages:
library(knitr)
library(kableExtra)
library(scales)

# Data packages:
library(fivethirtyeight)
library(nycflights13)
library(gapminder)
library(babynames)

# Etc
library(here)
library(patchwork)

# Set seed value of random number generator to get "replicable" random numbers.
set.seed(76)

# Example points for boxplots
example <- tibble(
  values = c(1, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 30)
)

# fruit basket example for data wrangling
fruit_basket <- tibble(
  type = c("mango", "kiwi", "mango", "grape", "grape", "mango"),
  `price in $` = c(2, 3, 1, 3, 1, 3)
)

# simple regression example
simple_regression_ex <- tibble(
  x = c(0, 0.5, 1),
  y = c(2, 1, 3)
)

# Note to future self: Changes y = value to something with context. Also saying
# "the fitted value for value" is awkweird
categ_regression_ex <- tibble(
  name = c("Bert", "Bert", "Bert", "Florence", "Florence", "Florence", "Katie", "Katie", "Katie"),
  value = c(9, 10, 11, 11, 12, 13, 8, 9, 10)
)
```



***



# Schedule 

<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQM-5FVt5BKJZsfElEV19NwD2MXGgSVUfGLB7dUoD0MbCU6Dkzqx66UMxbgqMaiS6H8CP8numV5Xaf-/pubhtml?gid=346882447&amp;single=true&amp;widget=true&amp;headers=false" width="100%" height="1015"></iframe>

<!--
{target="_blank"}
-->



***


# Lec 15: Fri 2/28

## Announcements

* `NA`

## Recap


## Chalk talk



***



# Lec 14: Wed 2/26

## Announcements

* `NA`

<!--
Show example of timestamped cover page of exam
-->

## Recap


## Chalk talk



***



# Lec 13: Mon 2/24

## Announcements

1. [SDS talk this week](https://smithcollege-sds.github.io/sds-www/speaker_Hu.html#public_lecture:_generating_synthetic_family_income_for_the_consumer_expenditure_surveys){target="_blank"} on balancing between "having useful data" and "maintinaing sufficient privacy protection":
    + What: "Generating Synthetic Family Income for the Consumer Expenditure Surveys"
    + Who: Prof. Jingchen (Monika) Hu, Vassar College
    + When: Thursday Feb 27, 5pm
    + Where: McConnell Hall 103

## Today


* Recap exercise on common R and RStudio coding issues (print-out given in class available [here](https://docs.google.com/document/d/1tvjDIZXlrQMaYKmv9omWkmIpi-2w3NPxGpNXlSktgNY/){target="_blank"})
* Discussion on [Badge Challenge 1](badge_challenges.html#)
* Class time for projects



***



# Lec 12: Fri 2/21

## Announcements

* `NA`

## Recap

Recall the `categ_regression_ex` data frame from from Lec11. Note that the explanatory variable $x$ = name is now categorical with 3 levels: Bert, Florence, Katie.

```{r, echo=FALSE, eval=TRUE}
categ_regression_ex
```

You then plotted the points. Let's also add three lines:

1. A solid line for Bert's "baseline" mean ("Bert" is the baseline because it comes first alphanumerically)
1. A dashed line for Florence's mean, which is *offset* from Bert's mean by 12 - 10 = +2
1. A dotted line for Katie's mean, which is *offset* from Bert's mean by 9 - 10 = -1

```{r, eval=TRUE, echo=FALSE}
ggplot(data = categ_regression_ex, mapping = aes(x=name,y=value)) +
  geom_point() +
  geom_hline(yintercept = 10) +
  geom_hline(yintercept = 12, linetype = "longdash") +
  geom_hline(yintercept = 9, linetype = "dotted")
```

Shout out to [Dr. Jenny Smetzer](https://www.scsparkscience.org/fellow/jennifer-smetzer/){target="_blank"} for this example.


## Chalk talk

Now let's obtain the *regression table* using the `get_regression_table()` function in the `moderndive` package. Recall this is done in two steps:

```{r, eval = TRUE}
# Step 1: Fit regression model
model_ex <- lm(value ~ name, data = categ_regression_ex)

# Step 2: Get regression table
get_regression_table(model_ex)
```


<!--
Then write on board (in order to bridge the gap between output of regression
table & wacked out indicator function notation they'll read in Chapter 5.2.2
today):

1. Make a separate table of name on rows, and nameFlorence and nameKatie in columns, populate with 0's & 1's
1. Write out equation of "line" in terms of regression table output:
    + `value = intercept + nameFlorence + nameKatie`.
    + Do all three cases
1. Write out equation of line via math and with indicator functions:
    + Explain what indicator function is $1_{Florence}(x)$
    + $\widehat{y} = b_0 + b_{Florence}\cdot 1_{Florence}(x) + b_{Katie}\cdot 1_{Katie}(x)$
    + We need this notation in particular for multiple regression in Chapter 6
--> 

Let's now get the fitted values and residuals using the `get_regression_points()` function on `model_ex` (where our model is saved):

```{r, eval = TRUE}
# Step 2: Get regression points
get_regression_points(model_ex)
```

<!--
Then write on board:

1. When x is categorical y-hat fitted values correspond to group means for each level:
    + Bert: Just 10
    + Florence: 10 + 2 = 12
    + Katie: 10 - 1 = 9
1. Compute a few residuals and show they correspond to deviations/errors from the group means

Note for future self: Make sure to talk about interpretation of the values in estimate column of table in context of example.

Note for future self:
- x numerical: for every slide of 1 in x, the slope is the expected/on average change in y (not necessarialy causal)
- x categorical: for a hop between categories starting from the baseline
-->



    
    
<!--    
If mental bandwidth exists, add to ModernDive -> Chapter 5.2.2 -> a visualization of what the terms in the regression table in Table 5.8 actually mean. Do this in  [moderndive_book](https://github.com/moderndive/ModernDive_book/) repo -> `bert-dev` branch -> Open `05-regression.Rmd` and edit, commit, and push this file only. The book builds and deploys automatically using Netlify

* A jitterplot of x = continent, y = lifeExp, mark baseline, mark means, show offsets of marked means vs baseline.
* Insert in text right before "Letâ€™s generalize this idea a bit".
-->



***



# Lec 11: Wed 2/19

## Announcements

* `NA`

## Recap

* What are boxplots good for?

<!--
Then write on board:

1. They allow you to compare the distribution of a numerical variable (on y-axis) split by a categorical variable (on x-axis)
1. Remember: solid line in middle is median, not mean. Both are measures of center, one is more sensitive to outliers.
1. Example: Say a company has 5 employees with hourly salary: 10, 10, 10, 10, 1000. Mean hourly salary is $208. Why might mean not be appropriate?
-->

## In-class exericse

Consider the following 9 points saved in a data frame called `categ_regression_ex` where we have

1. A numerical outcome variable $y$ = `value`
1. An *categorical* explanatory variable $x$ = `name` with 3 levels: Bert, Florence, Katie.

```{r, eval=TRUE}
library(ggplot2)
library(dplyr)
categ_regression_ex <- tibble(
  name = c("Bert","Bert","Bert","Florence","Florence","Florence","Katie","Katie","Katie"),
  value = c(9,10,11,11,12,13,8,9,10)
)
categ_regression_ex
```

In groups: copy the above code and create a scatterplot with

1. `value` (numerical) on the y-axis
1. `name` (categorical) on the x-axis

Note this is slightly different that the scatterplots we've seen until now where the x variable was always numerical.

```{r, echo=FALSE, eval=FALSE}
# This code is hidden. Maybe a live coding demo?
ggplot(categ_regression_ex, aes(x = name, y = value)) + 
  geom_point()
```

**Solution**:

```{r, eval=TRUE, echo=TRUE}
ggplot(data = categ_regression_ex, mapping = aes(x=name,y=value)) +
  geom_point()
```

<!--
Then draw the above plot on board and mark:

1. mean for Bert with horizontal line. call this the baseline mean
1. mean for Florence and Katie with horizontal lines
1. both possible offsets

Why is Bert baseline? For no other reason than it's first alphanumerically.
-->



***



# Lec 10: Mon 2/17

## Announcements

* First phase of [project](project.html) is due Mon 2/24 at 11pm. If you haven't already, **start now**. 
* Will Hopper's Thursday PM lab is cancelled b/c of Rally Day. For this week only, you may attend the following labs (see [syllabus](syllabus.html) for time/place):
    + David Rockoff's Tue PM lab
    + Will Hopper's Thu AM lab

## Recap

<!--
Bert is going to another example of summarize, b/c students are confused about 
the "collapsing rows" nature of the operation.
-->

## Chalk talk

1. Correlation is not necessarily causation:
    a) [Spurious correlations](http://www.tylervigen.com/spurious-correlations){target="_blank"}
    a) What are X = treatment, Y = response, and Z = confounding variables?
    a) What are causal graphs? 
    a) Simple example: Does "X = drinking gatorade/ginger ale" cause "Y = feel nauseous"? 
    <!--Z = has the flu -->
    a) Famous example: [UC Berkeley gender bias](https://en.wikipedia.org/wiki/Simpson%27s_paradox#UC_Berkeley_gender_bias){target="_blank"}. Does "X = (binary) gender" cause "Y = decreased chance of admission to UC Berkeley in 1973"?
    <!--Z = competitiveness of admissions to department. Women tended to apply to departments with less resources and thus were more competitive, like humanities, while men tended to apply to departments with more resources and thus were easier to get into, like engineering.--> 
1. Recall `simple_regression_ex` from Lec09.  
```{r, echo=FALSE, eval=TRUE}
simple_regression_ex
```
    a) Draw the 3 points and the "best-fitting" regression line in blue.
    a) Draw the 3 *fitted values* $\widehat{y}$ using the equation for the regression line $\widehat{y} = b_0 + b_1\cdot x$
    a) Draw the 3 *residuals* $y - \widehat{y}$
    a) Compute the sum of squared residuals for this line.
    a) Draw another arbitrarily chosen line with equation $\widehat{y} = 2 - 1\cdot x$ in green.
    a) Compute the sum of squared residuals for this line and compare to previous

```{r, echo=FALSE, eval=TRUE}
ggplot(simple_regression_ex, aes(x = x, y = y)) +
  geom_smooth(method = "lm", se = FALSE, size = 0.5) +
  geom_abline(intercept = 2, slope = -1, col = "darkgreen", linetype = "dashed", size = 0.5) +
  geom_point(size = 2)
```



***



# Lec 09: Fri 2/14

## Announcements

* If you need a group for the project, please fill out the Google Form on Moodle ASAP! We're going to start making groups this weekend.

## Recap

* `tidyverse` package is an umbrella package that loads `ggplot2`, `dplyr`, `readr`, and other useful packages for data science all at once. For more info, visit [tidyverse.org/](https://www.tidyverse.org/){target="_blank"}

## Chalk talk

Consider the following 3 points saved in a data frame called `simple_regression_ex`. 
```{r, echo=FALSE, eval=TRUE}
simple_regression_ex
```

Let's plot them along with the *regression line*.

Now let's obtain the *regression table*. This is done in two steps:
```{r, eval = TRUE}
# Step 1: Fit regression model
model_ex <- lm(y ~ x, data = simple_regression_ex)

# Step 2: Get regression table
get_regression_table(model_ex)
```

* Connection between regression line and values in `estimate` column of regression table.
* Interpretation of:
    + Fitted intercept $b_0$: mathematical versus practical interpretations.
    + Fitted slope $b_1$: precise language matters!
* Obtaining a regression table takes two steps:
    + Create/fit the model using `lm()` and formula interface `y ~ x`
    + Ask for the table using `get_regression_table()` function from `moderndive` package
    
<!--
Notes on precise interpretation of fitted slope b1: For every increase of one
unit in x, it is the associated average increase in y.

* average b/c not all differences of one unit in x have exactly b1 increase in y,
rather averaged across all differences of unit in x
* associated b/c we don't want to assume a casual relationship
-->



***



# Lec 08: Wed 2/12

## Announcements

* First phase of project unveiled: Project data (due Mon 2/24 at 11pm)
* We move to Chapters 5 & 6 on data modeling with regressions
* Keyboard shortcut for `%>%`:
    + macOS: Command + Shift + M
    + Windows: Contrl + Shift + M

## Recap

![](static/images/toolbox.jpeg){ width=50% }

Our data wrangling toolbox, which you will use for your project and for the rest of this course:

1. `filter()` rows
1. `summarize()` rows using a summary function
1. `group_by()` to group rows by the values of another variable
1. `mutate()` new variables/columns
1. `arrange()` rows in ascending (default) or `desc()`ending order
1. `select()` variables/columns
1. For more verbs, see `dplyr` cheatsheet: Go to RStudio menu bar -> Help -> Cheatsheets -> Data Transformation with `dplyr`.

<!--
Students get tripped up with difference between filter() and summarize(). The
former does not modify original rows, whereas the latter creates new ones that
are based on summary statistics.
-->



## Chalk talk

1. Correlation coefficient:
    + Definition: It is a summary statistic quantifying the strength of linear assocation. 
    + Draw examples
    + In ModernDive 5.4.1: Play "guessing the correlation game"
1. Two types of variables: outcome/response $y$ and explanatory/predictor variables $x$. For the following pairs of variables, what would be $y$ and what would be $x$ in a model?
    1. Temperature in fahrenheit vs temperature in celsius 
    1. Job salary and number of years of education
    1. Lung cancer and smoking
    1. Coffee and sleep

<!--
Next time 220 is taught: At this point in semester (Lec08-09) since students have a little context, consider doing a review of coding/computing concepts needed for this course:

- R console vs R Markdown are two different environments. i.e. when you create a variable/load a package in one, it doesn't necessarily exist in the other.
- Tackling error messages. Perhaps have a problem set where the students read error message and write down what the message is saying.
- Paired programming exercise: One student only writes, the other only asks questions.
- When getting help, steer students away from saying "This doesn't work" but rather "I did X. I got result Y. I think Z." That way we get what they're thinking better: building up to the idea of a minimally reproducible example. 
-->


***



# Lec 07: Mon 2/10

## Announcements

* Today's lecture is last of pink topics in calendar (data science). We start blue topics (regression) on Wednesday.

## Recap

## Chalk talk

* Using same fruit basket example from chalk talk in Lec 05:  
```{r, echo=FALSE, eval=TRUE}
fruit_basket
```
    1. `mutate()` new variables from existing variables: price in cents
    1. Reorder i.e. `arrange()` rows of a data frame in alpha-numerical order of a variable: in order of price. Default is ascending order, need to specify `desc()`
    1. `select()` variables/columns. Analogous to `filter()` rows.



***


# Lec 06: Fri 2/7

## Announcements

* `NA`
<!--
* Bert only: Emphasize problem set policy. "Turn in what you have."
* Bert only: Google doc exercise: https://docs.google.com/document/d/14PBmTU_wBTEI8j1lqZWFqFI3ETAD6N5qao-2ADQRTTM/edit

Write down 3 things you did for this class this week
Turn to a neighbor, come up with a list of 5 things
Then we did the google doc
-->

## Recap

<!--
* Bert only based on questions in his section: Distinguishing between
    + English use of "or" and "and" versus
    + Computer programming use of "or" and "and"
-->

## Chalk talk

* Using same fruit basket example from chalk talk in Lec 05:  
```{r, echo=FALSE, eval=TRUE}
fruit_basket
```
    1. "Summary functions" are many-to-one functions to compute "summary statistics," like `mean()` & `median()`
    1. Using summary functions to then `summarize()` rows
    1. Setting "group meta-data" of a data frame using `group_by()`, then `summarize()` rows. In other words, `group_by()` by itself does not change the "data", rather only the "meta-data"
* Normal distribution: One summary statistic of spread, standard deviation `sd()`, has a particular interpretation when distribution of a numerical variable follows a normal AKA bell curve



***




# Lec 05: Wed 2/5

## Announcements

* Posted single calendar of all instructor and lab instructor office hours on Moodle.
* Posted [badge challenges](badge_challenges.html)
* Managing Slack notifications:
    + We suggest but don't require installing Desktop App. 
    + If not, at the very least, keep email notifications on.
* How to approach in-class readings.
    
<!--
* Bert only: "not equals" and "bang equals"
-->

## Recap 

First, let's compare the boxplot you created in Lec04 with the original points. See how they align.

```{r, echo=FALSE, eval=TRUE}
plot1 <- ggplot(example, aes(x=factor(1), y=values)) +
  geom_point() +
  labs(title = "Points") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )

plot2 <- ggplot(example, aes(x=factor(1), y=values)) +
  geom_boxplot() +
  labs(title = "Boxplot") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
plot1 + plot2
```

Second, let's compare two visualizations of the distribution of the numerical variable temperature *split by* month:

* Faceted histogram in ModernDive [Figure 2.13](https://moderndive-bert.netlify.com/2-viz.html#facets){target="_blank"}
* Side-by-side boxplot in ModernDive [Figure 2.18](https://moderndive-bert.netlify.com/2-viz.html#boxplots){target="_blank"}

```{r, echo=FALSE, eval=TRUE}
ggplot(data = weather, mapping = aes(x = temp)) +
  geom_histogram(binwidth = 5, color = "white") +
  facet_wrap(~ month)
ggplot(data = weather, mapping = aes(x = factor(month), y = temp)) +
  geom_boxplot()
```

Which do you prefer?

Third, the idea of "assigning AKA saving something in R" using the arrow `<-`. Ex: `x <- 5`. You do this so you can access it again later, either to

1. View its contents: Type `x` in the console or RMarkdown.
1. Modify it's contents: Type `x <- x + 1` or RMarkdown. What is now saved in `x`?


## Chalk talk

We now start data wrangling! For our chalk talks, we'll use the following "fruit basket" example:

```{r, echo=FALSE, eval=TRUE}
fruit_basket
```

<br/>
Topics:

1. Define the "pipe operator" `%>%`, pronounced *then*
1. Logical AKA boolean operators in computer programming
1. `filter()` rows that match a criteria



***



# Lec 04: Mon 2/3

## Announcements

* `NA`

## Chalk talk

Boxplots! Powerful, but tricky!

Say we want to study the distribution of the following `r nrow(example)` values which are pre-sorted: 

> `r example %>% pull(values)`

They have the following *summary statistics*. A summary statistic is a single numerical value *summarizing* many values. Examples include the immediately obvious mean AKA average and median. Other less immediately obvious examples include:

* Quartiles (1st, 2nd, and 3rd) that cut up the data into 4 parts, each containing roughly one quarter = 25% of the data
* Minimum & maximum
* Interquartile-range (IQR): the distance between the 3rd and 1st quartiles

Min. | 1st Quartile | Median = 2nd Quartile  | 3rd Quartile  |  Max. | IQR
---- | ------- | ------  |  ------- | --- | ---
`r min(example$values)`  |  `r quantile(example$values, probs=0.25, type = 2)` |  `r median(example$values)`  |  `r quantile(example$values, probs=0.75, type=2)`  | `r max(example$values)` | 8 = 13.5 - 5.5


Steps to constructing a boxplot:

1. Draw box
1. Throw out whiskers 1.5 x IQR from either end of box
1. Mark outliers
1. Pull in the ends of both whiskers towards the box until an observed value is hit.



***



# Lec 03: Fri 1/31

## Announcements


## Chalk talk

1. Draw histogram by hand, emphasizing that bins correspond to intervals (right-edge inclusive).
1. Adjust the binning structure of the previous hand-drawn histogram two ways:
    + Adjusting the binwidth
    + Adjusting the number of bins
1. Facets split one graphic by the values of another variable (that does not have too many unique values).



***



# Lec 02: Wed 1/29

## Announcements

1. Fatima Keita is interested in organizing a group for students of color within SDS, called SDS coalition of color (SDSCC). She has also put together a survey to gather students of color's experiences within SDS courses and the program more generally. If you identify as a student of color and you've taken at least one SDS course, please take a moment to complete Fatima's [SDSCC Preliminary Interest Survey](https://www.surveymonkey.com/r/2YZ785Y){target="_blank"}. The idea is that these experiences would then be anonymously shared with the SDS faculty in hopes that we can work to improve inclusivity within the program and curriculum. If you are interested in joining, please email Fatima directly.
1. Show example `#questions` on Slack.
1. In-class demo of Gradescope.
1. This week's problem set has three elements
    + Submit PDF on Gradescope with questions tagged
    + Fill out Intro Survey Google Form
    + Submit on Moodle reflection piece which builds off in-class reflection exercise.
    
    
## Chalk Talk

1. Draw scatterplot by hand
1. Define of Grammar of Graphics
1. Write example `ggplot()` code
1. Explain what jittering does to graphic and what it does not do to original data



***



# Lec 01: Mon 1/27

## Announcements

* Introductions
* If you're having registration issues:
    + Please keep in mind that SDS201 is a course that also satisfies the intro stats pre-requisite for many majors, including PSY, GOV, BIO, NSC, ENV, and SDS. Please consider that option as it currently has lots of room.
    + If you are not registered for this course, fill out the waitlist [Google Form](https://docs.google.com/forms/d/e/1FAIpQLSdDfcVmrz8p2rmS2BXqT6tv3a-Syzn2gmIG88h4CYQzRvKltw/viewform){target="_blank"} before Thursday 5pm.
    + We will start informing students and signing green slips on Friday afternoon.
    + If you have previously put your name on the above waitlist Google Form but no longer need a spot, we would very much appreciate a message letting us know. This will help us and your peers a lot.
* Syllabus 
    + Honor code discussions
    + Reflection exercise
    
    
## Lecture

Here is the typical lecture flow:

* Start with a 10-15 minute "chalk talk". We do this to motivate the day's topics and warn you about potential pitfalls in understanding
* Followed by in-class ModernDive readings listed in the above schedule. We do this so you can read at your own pace, talk to your peers, and ask us questions. While you do not need to submit your "Learning Check" answers, we *highly* recommend you write them down and verify your answers in Appendix D of ModernDive.

Today's topics:

* Introduction to Slack: A brief demo
* Introduction to R, RStudio, and R packages: ModernDive readings
