
---
title: "Problem Set 07"
author: "Guest solutions author: Dr. Jenny Smetzer"
date: "2018-10-31"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: false
    df_print: kable
---

```{r, include=FALSE}
# Do not edit this code block/chunk
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2)
```

# Collaboration {-}

Please indicate who you collaborated with on this problem set: 



# Background {-}

Think back to the hate crimes data we used in Problem Set 02. The FiveThirtyEight article article about those data are in the Jan 23, 2017  ["Higher Rates Of Hate Crimes Are Tied To Income
Inequality"](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/)

We will use these data in this Problem Set to run regression models with a single categorical predictor (explanatory) variable. 

## Setup

First load the necessary packages 

```{r}
library(ggplot2)
library(dplyr)
library(moderndive)
library(fivethirtyeight)
```


Next let's explore the `hate_crimes` dataset in the `fivethirtyeight` package using the `glimpse()` function from the `dplyr` package:

```{r}
glimpse(hate_crimes)
```

You should also use the `View()` function to take a look at the data in the viewer Recall we can't have `View()` in an R Markdown document! And finally, type ?hate_crimes into the console to see a description of the variables in this data set. 

## Data manipulation

We will next add a new column to this data set that expresses the Share of 2016 U.S. presidential voters who voted for Trump as a categorical variable. Run this code below. 

```{r}
hate_crimes <- hate_crimes %>% 
  mutate(trump_support = cut_number(share_vote_trump, 3, 
                              labels = c("low", "medium", "high")))
```

The `cut_numbers` function used in the code above sorts the `share_trump_vote` variable from lowest to highest,  cuts it into three groups of roughly 17 states each (51/3). It categorizes all the lowest values as "low", the middle 17 values as "medium", and the top 17 values as "high". We have created a categorical variable! 


# Question 1: Trump support level

Let's model the relationship between:

* $y$: Hate crimes per 100K individuals in the 10 days after the 2016 US election as measured by the SPLC
* $x$: Level of Trump support in the state: `low`, `medium`, or `high`, as contained in the variable `trump_support` we created above.

## a) Visual model

1. Create a visual model of this data (a graph) that will allow you to conduct an "eyeball test" of the relationship between hate crimes per 100K and level of Trump support. Include appropriate axes labels and a title.
1. Comment on the relationship between these two variables.

```{r}
ggplot(data = hate_crimes, aes(x = trump_support, y = hate_crimes_per_100k_splc)) + 
  geom_boxplot() + 
  labs(x = "Voter Support of Trump", 
       y = "Number of Hate Crimes per 100K people", 
       title = "Trump is Evil")
```

Since the categorical variable `trump_support` is technially **ordinal** in that there is a low < medium < high hierarchy, we can state that the relationship between hate crime occurrent and state-level support for Trump is negatively related. In other words, as a state had lower support for Trump, so also did they have more occurrences of hate crimes. **Say what?**

## b) Regression model

Now run a model that examines the relationship between hate crime rates and the level of Trump support. Generate a regression table.

```{r}
hate_model <- lm(hate_crimes_per_100k_splc ~ trump_support, data = hate_crimes)
get_regression_table(hate_model)
```

1. What does the intercept mean in this regression table?
1. What does the model estimate as the number of hate crimes per 100000 people in states with  "low" Trump support?
1. Does the model estimate that hate crimes are more frequent in states that show "low" or "medium" support for Trump?
1. What does the model predict as the number of hate crimes per 100000 people in states with  "high" Trump support?
1. What are the three possible fitted values $\widehat{y}$ for this model? (Hint: use the `get_regression_points`) function to explore this if you are not sure!

Write your answers here (if possible in an enumerated list just like above): 

1. the "low" Trump support states had on average 0.460 incidents per 100K. This is
the baseline for comparision.
1. the "medium" Trump support states had on average 0.460 - 0.238 = 0.222
incidents per 100K. So the estimate of -0.238 is difference relative to the
baseline.
1. the "high" Trump support states had on average 0.460 - 0.269 = 0.191 incidents
per 100K. So the estimate of -0.269 is difference relative to the baseline.
1. 0.191 incidents per 100K
1. They are the group averages: 0.460, 0.222, 0.191. See below

```{r}
hate_crimes %>% 
  group_by(trump_support) %>% 
  summarize(avg_hate_crime_rate = mean(hate_crimes_per_100k_splc, na.rm = TRUE)) %>% 
  mutate(avg_hate_crime_rate = round(avg_hate_crime_rate, 3))
```

Note we need to add the `na.rm = TRUE` inside of the `mean()` function because of
the `NA` values for Hawaii, South & North Dakota, and Wyoming as seen in the map
in the original 538 article.


## c) Questions

For these questions, showing your work is optional; solve it any way you choose. 

1. Which 5 states had the highest rate of hate crimes? Describe levels of Trump support in these 5 states.
1. Which 5 states had the lowest rate of hate crimes? Describe levels of Trump support in these 5 states.
1. Do these results surprise you? There is no right answer to this question

Write your answers here (if possible in an enumerated list just like above): 

1. DC, Oregon, Washington, MA, Minnesota- These states all had "low" Trump support. 
1. Ol Miss, Arkansas, Dirty Jersey and Rhode Island the stinky cousin. These first two states had high Trump support, the second two had low support
1. Super surprised. There must be another variable that is driving this that needs to be accounted for our in models that currently is not. 


# Question 2

For this exercise, we will model the relationship between 

* $y$: Hate crimes per 100K individuals in the 10 days after the 2016 US election as measured by the SPLC
* $x$: Level of unemployment in the state: `low`, or `high`. We will create this categorical variable. 

Using the tools and code examples from above, complete the following tasks:

## a) data manipulation

1. Make a new **categorical** variable called `unemployment` that has **two** levels, "low" and "high" based on the variable `share_unemp_seas`. 

```{r}
hate_crimes <- hate_crimes %>% 
  mutate(unemployment = cut_number(share_unemp_seas, 2, labels = c("low", "high")))
```

## b) visual data exploration 

Create a visual model of this data (a graph) that will allow you to conduct an "eyeball test" of the relationship between hate crimes per 100K and unemployment level. Include appropriate axes labels and a title.

```{r}
ggplot(data = hate_crimes, aes(x = unemployment, y = hate_crimes_per_100k_splc)) + 
  geom_boxplot() + 
  labs(x = "State unemployment level", 
       y = "Number of Hate Crimes per 100K people", 
       title = "Trump is Evil")
```

## c) running the model

Now run a model that examines the relationship between hate crime rates and the unemployment level. Generate a regression table.

```{r}
job_model <- lm(hate_crimes_per_100k_splc ~ unemployment, data = hate_crimes)
get_regression_table(job_model)
```

## d) interpreting the model

Answer the following questions:

1. What does the intercept mean in this regression table?
1. What does the model estimate as the number of hate crimes per 100000 people in states with  "high" unemployment?
1. What are the two possible fitted values $\widehat{y}$ for this model? Why are there only two this time? (there were three in the last question)

Answer the questions here:

1. It shows the estimated average hate crime rate for the states with the low unemployment
1. This would be 0.32 - 0.031 = 0.289
1. The two possible fitted values are 0.32 and 0.289, for the low and high employment groups respectively.

## e) interpreting residuals

Use the `get_regression_points` function to generate a table showing the predictions, and the residuals. How are the residuals calculated here? 

```{r}
get_regression_points(job_model) %>% 
  head()
```

Answer the question here: 

They are calculated by subtracting the predicted hate crime value from the observed hate crime. 
For instance, in the first row. 0.126 - 0.289 = -0.163
