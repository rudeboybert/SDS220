
---
title: "Problem Set 05"
author: "WRITE YOUR NAME HERE"
date: "2018-10-07"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: false
    df_print: kable
---

```{r, include=FALSE}
# Do not edit this code block/chunk!
knitr::opts_chunk$set(
  echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, 
  fig.height = 9/2
)

# Load necessary packages
library(ggplot2)
library(dplyr)
library(moderndive)
library(readr)

# Set pseudo-random number generator seed value
set.seed(76)
```


# Collaboration

Please indicate who you collaborated with on this problem set: 



# Question 1: Ch 6 Learning Checks

You'll be completing slightly modified versions of the Learning Checks from
Chapter 6 of ModernDive. Recall we are using the `evals` dataset with 

* Outcome variable y = teaching score
* Explanatory variable x = age

As a refresher, let's look at a random sample of 5 of 463 professors using
the `sample_n()` command from the `dplyr` package

```{r}
evals %>% 
  sample_n(5)
```


## LC 6.1: EDA

Write the code to perform the following exploratory data analysis:

1. Create a visualization that allows you conduct an "eyeball" test of the
relationship between teaching score and age.
1. Compute a summary statistic of the *strength of linear association* of these
two variables.

**Solution**: Note we use `geom_point()` keeping in mind that there is overplotting in the points. We could've also used `geom_jitter()`, but this was not necessary. Note we see a negative relationship between these two variables, however this relationship appears only weakly negative. In other words, as professors age, their teaching scores tend to drop. 

```{r}
# 1. Code for visualization:
ggplot(evals, aes(x = age, y = score)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", title = "Relationship of age and beauty scores") +
  geom_smooth(method = "lm", se = FALSE)
```

The correlation coefficient measures the strength of linear association, or the degree to which points fall on a line. Here it is -0.107, which is consistent with our earlier image of a weakly negative relationship. 
```{r}
# 2. Code for summary statistic:
evals %>% 
  get_correlation(formula = score ~ age)
```

Based on these two outputs, comment on the relationship between teaching score
and instructor age for these 463 instructors at the University of Texas Austin.
Do this in three sentences or less below:

**Solution**:  There seems to be a weak negative relationship. The slope of the
regresion line is negative, also the correlation coefficient of -0.107 is weakly
negative. Meaning as professors age, there is an associated decrease in teaching
score.



## LC 6.2: Regression table

Do the following in the code block below:

1. Fit the corresponding regression model and save this in `score_model_age`
1. Output the regression table

```{r}
# 1. Fit regression model:
score_model_age <- lm(score ~ age, data = evals)
```

```{r}
# 2. Output regression table:
get_regression_table(score_model_age)
```

**Part a)** What is the numerical value of the intercept? What, according to this model, is the teaching score for teachers with age 0?  Is there any real practical interpretation of the intercept in this case? Note that you can verify these results by comparing them with the visualization above. Write your answer below:

**Solution**: Intercept $b_0$: 4.46. This is the average teaching score of a professor with age = 0. While the intercept has a mathematical interpretation (it situates the vertical location of the line) it does not have a practice one. 

**Part b)** What is the slope? On average, how much does teaching score go down each year for a professor? Note that you can verify these results by comparing them with the visualization above. Write your answer below:

**Solution**: Slope $b_1$: -0.00600. For every increase in one year in age, there is on average an associated decrease of 0.00600 units in teaching score. This is an explicit quantification of our "eye-ball test" above.


**Part c)** Say an a new instructor of age 45 joins the faculty at the UT
Austin. Knowing nothing else about this instructor, what would you predict their
teaching score to be? Show your work:

**Solution**:

$$\widehat{\mbox{score}} = b_0 + b_{\mbox{age}} * \mbox{age} = 4.46 -0.006 * 45 = 4.19$$

We predict a teaching score of 4.19. There are likely more factors than just age
when predicting teaching score, hence the need for multiple regression.






# Question 2:

Recall the following data/visualization from Question 1 on the [practice
midterm](https://rudeboybert.github.io/SDS220/static/exams/Midterm-I_practice.pdf):

```{r}
DD_vs_SB <- read_csv("https://rudeboybert.github.io/SDS220/static/PS/DD_vs_SB.csv")

ggplot(DD_vs_SB, aes(x = med_inc, y = shops_per_1000, col = Type)) +
  geom_point() + 
  facet_wrap(~Type) +
  geom_smooth(method = "lm", se = FALSE, col = "blue") + 
  labs(x = "Median Household Income", y = "# of shops per 1000 people", 
       title = "Coffee/Cafe Comparison in Eastern MA") +
  scale_color_manual(values=c("orange", "forestgreen"))
```

Write the code in the code block below that will allow you to answer the
following two questions:

1. For every increase in $10K in median income, there is an associated **decrease**
of on average how many Dunkin Donuts shops per 1000 individuals?
1. For every increase in $10K in median income, there is an associated **increase**
of on average how many Starbucks per 1000 individuals?

## Solutions: Four Steps to Follow

This is definitely a tough question, because it borrows elements from
the entire [data science pipeline](https://rudeboybert.github.io/SDS220/term_project.html).
However, it makes good practice for your final projects!

1. Separating Dunkin Donuts data from Starbucks Data
1. Fitting two regression models & outputing two regression tables, one for Dunkin Donuts, the other for Starbucks
1. Creating a new variable: "median income in tens of thousands of dollars"
1. Fitting two new regression models & outputing two new regression tables, using "median income in tens of thousands of dollars" instead of "median income" as the explanatory variable.


## Step 1: Separating DD data from SB Data

We use the `dplyr` package's `filter()` function to make two separate data
frames: one of only the rows corresponding to Dunkin Donuts and the other only
of the rows corresponding to Starbucks:

```{r}
DD <- DD_vs_SB %>% 
  filter(Type == "Dunkin Donuts")
SB <- DD_vs_SB %>% 
  filter(Type == "Starbucks")
```

Run `View()` on both of these to convince yourself that `DD` only contains
Dunkin Donuts data and `SB` only contains Starbucks data. Let's also look at the 
data using `glimpse()` below, which provides a different perspective of
the same data.

```{r}
glimpse(DD)
glimpse(SB)
```


## Step 2: Fitting two regression models & outputing two regression tables

Let's fit the regression model for just the Dunkin Donuts `DD` data frame.

```{r}
# 1. Fit regression model:
DD_model <- lm(shops_per_1000 ~ med_inc, data = DD)

# 2. Get regression table for Dunkin Donuts:
get_regression_table(DD_model)
```

Weird! The regression table is telling us the slope for median income is zero!
But looking at the figure above, the slope is clearly negative, albeit only
slightly negative. However, is the slope in the regression table truly "0", or 
is it so small that its rounded to "0"?

We notice the same problem with the Starbucks data:

```{r}
# 1. Fit regression model:
SB_model <- lm(shops_per_1000 ~ med_inc, data = SB)

# 2. Get regression table for Starbucks:
get_regression_table(SB_model)
```


The issue is the associated effect of changes of \$1 in median income on the
number of Dunkin Donuts per 1000 people aren't big enough to notice! However, if
we consider changes of \$10,000 = \$10K in median income, then perhaps they will
be noticeable!




## Step 3: Creating a new variable 

We created a new variable `med_inc_in_10K` which is median family income in tens
of thousands of dollars! So for example, `36000` becomes `36000/10000 = 3.6` in
units of ten thousand dollars!

```{r}
DD <- DD %>% 
  mutate(med_inc_in_10K = med_inc/10000)
SB <- SB %>% 
  mutate(med_inc_in_10K = med_inc/10000)
```

Run `View()` on both of these to convince yourself that `med_inc_in_10K` is equal
to `med_inc / 10000`. Let's also look at the 
data using `glimpse()` below, which provides a different perspective of
the same data.

```{r}
glimpse(DD)
glimpse(SB)
```


## Step 4: Fitting new regression models & outputing new regression tables

Let's fit a new regression model where we use `med_inc_in_10K` instead of `med_inc`
as the explanatory variable:

```{r}
# 1. Fit new regression model:
DD_model_new <- lm(shops_per_1000 ~ med_inc_in_10K, data = DD)
# 2. Get new regression table for Dunkin Donuts:
get_regression_table(DD_model_new)
```

We now see that the slope is indeed negative! -0.004 to be exact! In other words,
there is a negative relationship between the number of Dunkin Donuts in a 
census track and median household income. 

Let's repeat for Starbucks:

```{r}
# 1. Fit new regression model:
SB_model_new <- lm(shops_per_1000 ~ med_inc_in_10K, data = SB)

# 2. Get new regression table for Dunkin Donuts:
get_regression_table(SB_model_new)
```

We see the slope is indeed positive! 0.004! In other words,
there is a negative relationship between the number of Dunkin Donuts in a 
census track and median household income. 

**What's the story to be told?** These models are suggesting that

* Dunkin Donuts tend to locate in lower income areas. 
* Starbucks tend to locate in higher income areas.
