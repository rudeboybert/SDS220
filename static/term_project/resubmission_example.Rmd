
---
title: "Predictive Factors of Math SAT Score in Massachusetts Public and Charter High Schools"
author: "Albert and Jenny"
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    theme: lumen
    toc: yes
    toc_depth: 2
    df_print: kable
    toc_float:
      collapsed: no
---

```{r, include=FALSE}
# Do not edit this code block/chunk
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2)
```


![](https://i2.wp.com/www.markstivers.com/cartoons/Stivers%2011-9-02%20SAT%20waiter.gif?zoom=2_
https://i2.wp.com/www.markstivers.com/cartoons/Stivers%2011-9-02%20SAT%20waiter.gif?zoom=2_
)

```{r}
library(ggplot2)
library(dplyr)
library(janitor)
library(moderndive)
library(readr)
library(tidyr)
library(knitr)
```

```{r}
# Read in data. Follow these steps: 
# https://twitter.com/rudeboybert/status/1055821833512071168
ma_schools <- read_csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vSrWSNyNqRVA950sdYa1QazAT-l0T7dl6pE5Ewvt7LkSm9LXmeVNbCbqEcrbygFmFyK4B6VQQGebuk9/pub?gid=1469057204&single=true&output=csv")

```

```{r, eval = FALSE}
# Preview your data using glimpse(). Note:
# * The output of this code chunk does not show since eval = FALSE, meaning
# "do not evaluate i.e. run this code chunk"
# * View() will cause R Markdown to not knit
glimpse(ma_schools)
```

```{r}
# Data wrangling

# This selects fewer variables for now, to make the "wrangling" easier
ma_schools_categ <- ma_schools %>%
  select("School Name",
         "11_Enrollment",
         "12_Enrollment",
         "TOTAL_Enrollment",
         "Economically Disadvantaged",
         "% Economically Disadvantaged",
         contains("SAT"))

# This cleans up the names of the variables using the janitor package's 
# clean_names() function. See: 
# https://twitter.com/rudeboybert/status/963504925744488450
ma_schools_categ<- ma_schools_categ %>% 
  clean_names() 

# This converts the numerical variable total_enrollment into categorical by 
# "cutting" into three chunks. Then for aesthetic purposes change the school 
# size category names to: Small, Medium, and Large
ma_schools_categ <- ma_schools_categ %>% 
  mutate(school_size = cut_number(total_enrollment, n=3)) %>%
  mutate(size = recode_factor(school_size, 
                              "[0,341]" = "Small",
                              "(341,541]" = "Medium",
                              .default = "Large"))

# Next we filter the rows to only include schools that had 11th and 12th grade students
ma_schools_categ <- ma_schools_categ %>%
  filter(x11_enrollment > 0 & x12_enrollment > 0)

# Here we select our identification, outcome, and explanatory variables
high_schools_data <- ma_schools_categ %>%
  select("school_name", contains("sat"), "percent_economically_disadvantaged", "size")

# Here we convert our "wide" data set into a "tidy" AKA tall one using the 
# gather() function from the tidyr pacakge. See moderndive chapter 4 for more 
# details. We gathered the three SAT test columns into rows, under the column 
# name "sat_type" and "score"
high_schools_data_sat <-gather(high_schools_data, "sat_type", "score", 3:5)%>%
  filter(sat_type == "average_sat_math")

# Here is the final, cleaned, tidy data set with the ID variable, 
# outcome variable, numeric x, categorical x
high_schools_data_sat <- high_schools_data_sat %>% 
  select(school_name, score, percent_economically_disadvantaged, size)
```

Here is a snapshot of the first 5 rows of the data we'll use:

```{r}
# Output a preview in RMarkdown of only the first 5 rows using dplyr's slice()
# function
high_schools_data_sat %>% 
  slice(1:5)
```


***


# 1. Introduction 

Many schools in the US are failing^[Strauss, Valerie. _What the numbers really tell us about America's public schools_. Washington Post, March 2017.  _https://www.washingtonpost.com/news/answer-sheet/wp/2017/03/06/what-the-numbers-really-tell-us-about-americas-public-schools/?noredirect=on&utm_term=.d9a5b415678d]. This study aims to better understand how school conditions influence student performance. The SATs are an important part of many high school senior's college application, and represent one measure of student performance. Our project investigates whether factors such as the percentage of economically disadvantaged students in a school and school size are related to student performance, as measured by a schools' average SAT score. 

To address this question, we used a data set from Kaggle that compiled information on public and charter schools in the state of Massachusetts from several Massachusetts Department of Education reports^[Dalziel, Nigel. _Massachusetts Public Schools Data_. Kaggle, Aug. 2017. Web. 19 Oct. 2018. https://www.kaggle.com/ndalziel/massachusetts-public-schools-data]. The data was last updated in August of 2017. Each case in the data set is a school. Although this data set includes schools with grades K-8, we only focused on high school with 11th and 12th grades, as these are the grades in which students typically take SAT scores. 

Unfortunately, the data does not contain overall SAT scores, only averaged Math and Verbal and Writing SAT scores for each school. After doing an exploratory data analysis, we saw that these three sub-types demonstrated similar trends. Therefore, we decided to focus solely on the Math SAT score (out of 800 points) as our outcome variable in order to make this report more concise. We included two explanatory variables in this analysis: the percent of students in a school that are considered economically disadvantaged, and school size, with three levels, "small" (< 342 students), "medium" (342-541 students), and "large" (> 541 students). 


***


# 2. Exploratory data analysis

We had a sample size of 390 high schools; however, since 58 of these had missing SAT scores, our total sample size was `r 390-58` (Table 1). The mean of the average SAT scores was greatest for large schools ($n = 238$, $\bar{x} = 517.5$, $sd = 56.2$), intermediate for medium schools ($n = 74$, $\bar{x} = 483.3$, $sd = 58.7$), and lowest for small schools ($n = 78$, $\bar{x} = 478.0$, $sd = 77.4$). In MA in 2017, the average percentage of economically disadvantaged students in schools was 31 % ($SD = 21.74), 

The percentage of students that were considered economically disadvantaged ranged from 3.1% to a shockingly high 93.9% ($\bar{x} = 31.6$, $sd = 21.7$). 

```{r}
high_schools_data_sat %>% 
  summarize(min = min(percent_economically_disadvantaged), 
            max = max(percent_economically_disadvantaged), 
            mean = mean(percent_economically_disadvantaged), 
            sd = sd(percent_economically_disadvantaged))
```



***

Table 1. Summary statistics of average Math SAT scores for small, medium and large high schools in the State of Massachusetts in 2017.

```{r }
high_schools_data_sat %>% 
  group_by(size) %>% 
  summarize(n = n(), 
            xbar = mean(score, na.rm = T), 
            Mdn = median(score, na.rm = T), 
            sd = sd(score, na.rm = T), 
            min = min(score, na.rm = T), 
            max = max(score, na.rm = T)) %>% 
  kable(digits = 2)
```

***


Since the data were not skewed, and looked normally distributed we did not do any transformations (Fig. 1). We did notice a potential outlier around a score of 750, which is something to consider throughout our analysis.

```{r, fig.cap = "Figure 1. Distribution of average Math SAT scores in the State of Massachusetts in 2017", fig.align = "center"}
ggplot(high_schools_data_sat, aes(x = score)) +
  geom_histogram(binwidth = 30, color = "white", fill = "steelblue") +
  labs(x = "Average Math SAT Score", y = "Frequency") 
```

We generated a scatterplot to see the relationship between our numerical explanatory variable, percentage of economically disadvantaged students, and our numerical outcome variable, Math SAT score (Fig. 2). As the percentage of economically disadvantaged students increased, there was an associated decrease in Math SAT score. Reflecting this we calculated a correlation coefficient of -0.83. 

```{r}
high_schools_data_sat %>%  
  filter(!is.na(score)) %>%
  summarize(cor(score, percent_economically_disadvantaged))
```

```{r, fig.cap = "Figure 2. Scatterplot illustrating the relationship between Percentage of Economically Disadvantaged Students and Math SAT Score in MA Schools in 2017", fig.align = "center"}

#Scatterplot of %Disadvantaged vs. Score
ggplot(high_schools_data_sat, aes(x = percent_economically_disadvantaged, y = score))+
  geom_point() +
  geom_smooth(method = "lm", se = FALSE ) +
  labs(y = "Math SAT Score", x = "Percentage of Economically Disadvantaged Students")
```

The Math SAT scores look to be the greatest at larger schools, and the lowest at smaller schools, though the difference does not seem to be extreme (Fig. 3). There appear to be some potential outliers.  In particular, there is one small school with a very high average SAT score. Small schools also have the largest interquartile range (Fig. 3).

```{r, fig.cap = "Figure 3. Boxplot showing Math SAT score for each school size category", fig.align = "center"}
ggplot(high_schools_data_sat, aes(x = size, y = score)) +
  geom_boxplot(fill = c("sienna", "darkgreen", "steelblue")) +
  labs(y = "Math SAT Score", x = "School Size")
```

Finally, we generated a scatterplot of SAT score against percent of economically disadvantaged students split by school size (Fig. 4).  The slopes of the lines of each size school appear to be fairly similar, and parallel. There does not appear to be a need to include an interaction effect in our model. 

```{r, fig.cap = "Figure 4. Scatterplot illustrating the relationship between Percentage of Economically Disadvantaged Students and Math SAT Score in MA Schools of different sizes in 2017", fig.align = "center"}
ggplot(high_schools_data_sat, aes(x = percent_economically_disadvantaged, y = score, color = size))+
  geom_point() +
  geom_smooth(method = "lm", se = FALSE ) +
  labs(y = "Math SAT Score", x = "Percentage of Economically Disadvantaged Students")
```



***



# 3. Multiple linear regression

## 3.1 Methods

The components of our multiple linear regression model are the following:

* Outcome variable = Math SAT score
* Explanatory numerical variable = Percentage of students who are economically disadvantaged
* Explanatory categorical variable = School size

We will use multiple linear regression to test two different null hypotheses. The first null hypothesis is that there is no relationship between the percentage of economically disadvantaged students and Math SAT score at the population level (the population slope is zero).

$$\begin{aligned} H_0:&\beta_{prct} = 0 \\\ \mbox{vs }H_A:& \beta_{prct} \neq 0 \end{aligned}$$

The second null hypothesis that we are testing is that there is no relationship between school size and Math SAT score at the population level. 

$$\begin{aligned} H_0:&\mu_{small} = \mu_{med} = \mu_{large} \\\ \mbox{vs }H_A:& \mu_{small} \neq \mu_{med} \neq \mu_{large}  \end{aligned}$$

We did not include an interaction effect because the slopes appear to be reasonably parallel (Fig. 4).


## 3.2 Model Results

***

Table 2. Parallel slopes model relating Math SAT score to school size, and percentage of economically disadvantaged students.
 
```{r}
math_model <- lm(score ~ percent_economically_disadvantaged + size, data = high_schools_data_sat)
get_regression_table(math_model)
```

***

## 3.3 Interpreting the regression table

The intercept ($\beta_0 = 88.19$) represents the Math SAT score when zero percent of the students are said to be economically disadvantaged and the school size is small (Table 2). The estimate for the percent_economically_disadvantaged ($\beta_ {prct} = -2.77$) is the associated change in score depending on the percentage of economically disadvantaged students. Based on this estimate, for every 1% increase in the percent of economically disadvantaged students in a school, MATH SAT scores went down on average by 2.78 points. The estimate for sizeMedium ($\beta_ {med} = -11.91$) and sizeLarge ($\beta_ {large} = -6.36$) are the offsets in intercept relative to the baseline group's, sizeSmall, intercept (Table 2). 

The regression equation for Math SAT score is the following:

$$ \begin{aligned}\widehat {score} = & \beta_ {0} + \beta_ {prct} \times percent\_economically\_ disadvantaged + \beta_ {med} \times 1_{is\ med} + \beta_ {large} \times 1_ {is\ large} \\\ \widehat {score}=& 588.19 - 2.78 \times percent\_ economically\_ disadvantaged - 11.91 \times 1_{is\ med} - 6.36 \times 1_ {is\ large} \end{aligned} $$


## 3.4 Inference for multiple regression

There was a significant negative relationship between the percent of economically disadvantaged students and mean SAT score for schools ($\beta_{prct} = -2.77$, $p < 0.001)$, Table 2). Reflecting this, the 
95% confidence interval for $\beta_{prct}$  (-2.99, -2.57) did not include zero. At an $\alpha = 0.05$ we can reject the null hypothesis that economic disadvantage has no effect on Math SAT score at the population level. 

SAT scores were lower in medium schools compared to small schools; however, this difference was not statistically significant ($\beta_{med} = -11.91$, $p = 0.12$, Table 2). Reflecting this, the 95% confidence interval for $\beta_{med}$ overlaps zero (-26.74, 2.91). SAT scores were also lower in large schools compared to small schools; however, this difference was not statistically significant ($\beta_{lg} = -6.36$, $p = 0.36$, Table 2). Reflecting this, the 95% confidence interval for $\beta_{large}$ overlaps zero (-19.98,	7.26, Table 2). Therefore, at an $\alpha = 0.05$ we we fail to reject the null hypothesis that school size has no effect on Math SAT score. 

## 3.5 Residual Analysis

We conducted a residual analysis to see if there was any systematic pattern of residuals for the statistical model we rand.  

```{r, fig.cap = "Figure 5. Distribution of residuals for statistical model", fig.align = "center"}
regression_points <- get_regression_points(math_model)
ggplot(regression_points, aes(x = residual)) +
  geom_histogram(binwidth = 20, color = "white", fill = "steelblue")+
  labs(x = "Residual")
```

<br> 

```{r, fig.cap = "Figure 6. Scatterplots of residuals against the numeric explanatory variable.", fig.align = "center"}
ggplot(regression_points, aes(x = percent_economically_disadvantaged, y = residual)) +
  geom_point() +
  labs(x = "Percentage of Economically Disadvantaged Students", y = "Residual") +
  geom_hline(yintercept = 0, col = "blue", size = 1)
```

<br> 

```{r, fig.cap = "Figure 7. Scatterplots of residuals against the fitted values.", fig.align = "center"}
ggplot(regression_points, aes(x = score_hat, y = residual)) +
  geom_point() +
  labs(x = "Fitted Values", y = "Residual") +
  geom_hline(yintercept = 0, col = "blue", size = 1)
```

<br> 

```{r, fig.cap = "Figure 8. Boxplot of residuals for each school size.", fig.align = "center"}
ggplot(regression_points, aes(x = size, y = residual)) +
  geom_boxplot(fill = c("sienna", "darkgreen", "steelblue")) +
  labs(x = "School size", y = "Residual") +
  geom_hline(yintercept = 0, col = "blue", size = 1)
```

The model residuals were normally distributed, though there was one potential outlier (Fig. 5). There are not any systematic patterns to either of the scatterplots (Fig 6 & 7). There is, however, one clear outlier around 5% in Figure 6 and at a very high mean SAT score in Figure 7. The boxplots show a very even spread of residuals at each school size, and similar values across the different school sizes. However, there is again, one particularly extreme outlier in the small school group (Fig. 8). We conclude that the assumptions for inference in multiple linear regression are well met. However, it might be worthwhile to look at whether the outlier with the very high scoring small school (MA Academy for Math and Science School) had a very large influence on the conclusions. 

We quickly re-ran the model with the very high scoring small school removed (Table 3). We would again reject the first null hypothesis, and not reject the second. The data again supports a significant negative relationship between the percent of economically disadvantaged students and Math SAT scores. Thus we assumed that this outlier did not have an extreme influence on our results. 


***

Table 3. Parallel slopes model relating Math SAT score to school size, and percentage of economically disadvantaged students, with the outlier of the MA Academy for Math and Science School removed. 

```{r}
data_subset <- high_schools_data_sat %>% 
  filter(score != 741)

math_model2 <- lm(score~ percent_economically_disadvantaged + size, data = data_subset)
get_regression_table(math_model2)
```

***



# 4. Discussion 

## 4.1 Conclusions

We found that there was no significant difference in Math SAT scores at different sized schools, but that as the percentage of economically disadvantaged students increased, the scores decreased significantly. On average, Math SAT scores decreased by approximately 3 points for every 1% increase in percentage of economically disadvantaged students. This however does not necessarily mean that economic disadvantage *causes* lower test scores. We were surprised to find that school size did not have a significant influence on SAT scores. We expected to see higher SAT scores in small schools, assuming that students could get more one-on-one attention from teachers. 

Overall, these results suggest that the economic well being of families is a factor in academic success. Our findings are consistent with previous studies showing that found wealth is correlated to SAT scores in the US^[Goldfarb, Zacchary. _These four charts show how the SAT favors rich, educated families_. Washington Post. March 2014. https://www.washingtonpost.com/news/wonk/wp/2014/03/05/these-four-charts-show-how-the-sat-favors-the-rich-educated-families/?noredirect=on&utm_term=.aac2fb6c0f32].  In order to mitigate this, we believe that there should be more support systems in schools with higher percentages of economically disadvantaged students. These could include free SAT prep courses or college readiness programs. Furthermore, programs that help remove barriers to education (transportation, hunger, etc.) may benefit overall student learning, and outcomes. The trends found in this analysis are important because SAT scores are a factor for college acceptances, which in our current society is a often a prerequisite for higher paying jobs.

## 4.2 Limitations

There were several limitations to this data set. For one, 58 out of the 390 high schools were missing SAT score data. A close inspection revealed that these were mostly small schools in which less than five students took the SAT.  Furthermore, these data only for the state of Massachusetts in 2017. As such, our scope of inference is limited to Massachusetts; it may not be appropriate to generalize the results found to the country as a whole. Massachusetts has been ranked #1 for public school systems by multiple sources including Forbes, and this may affect the trends seen in the data relative to other states^[Morad, Renee. _States With The Best Public School Systems_ Forbes, Forbes Magazine, August 2018, https://www.forbes.com/sites/reneemorad/2018/07/31/states-with-the-best-public-school-systems/#649330883897]. Additionally, a low score on the Math subsection is not necessarily indicative of a low total SAT score. However, since total SAT scores were not included in this data set, this was not a measure we could look at. Finally, standardized test results and graduation rates were the only measures of student success in this data set. We chose SAT scores as our outcome variable for this study due to this limitation. However, we recognize that standardized testing is not likely the best indicator of student success and intelligence. Not every school requires their students to take the SAT and these tests are expensive, which can act as a barrier for some students. 

## 4.3 Further questions

If we were to continue researching this topic, we would like to work with a data set that includes total SAT score instead of just the sub-type scores. This would give us a better idea of the students' performance. It would be ideal to use a data set also includes several years worth of data so that we can see if the trends shown persist from year to year. Finally, it would be interesting to incorporate other explanatory variables, particularly ones that policy makers could address through funding programs or laws. The results from this sort of study could be given to the state of Massachusetts so they can make more informed decisions about their schools.

Since our results strongly suggest that money is correlated to success on the SAT, it would be interesting to investigate the distribution of federal and state funding to public and charter schools in the state of Massachusetts. 

We would also like to expand from just Massachusetts to other states across the country to get a broader view of the United States public education system. Massachusetts is a leader in education^[Reis, Jacqueline. _Massachusetts Students Score among World Leaders on PISA Reading, Science and Math Tests_. Department of Education News, December 2016. http://www.doe.mass.edu/news/news.aspx?id=24050]. Many states are very different from Massachusetts and therefore could yield different results than what we found in this project. 



***


# 5. Citations and References {-}

